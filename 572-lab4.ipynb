{"metadata":{"accelerator":"GPU","colab":{"name":"lab4.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"vscode":{"interpreter":{"hash":"f821000d0c0da66e5bcde88c37d59c8e0de03b40667fb62009a8148ca49465a0"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src=\"img/dsci572_header.png\" width=\"600\">","metadata":{"colab_type":"text","id":"lYUHk6sxO2pO"}},{"cell_type":"markdown","source":"# Lab 4: Transfer Learning and GANs","metadata":{}},{"cell_type":"markdown","source":"## Instructions\n<hr>\n\nrubric={mechanics:5}","metadata":{}},{"cell_type":"markdown","source":"- Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/)\n\n- Upload a PDF version of your lab notebook to Gradescope, in addition to the .ipynb file.\n\n- Add a link to your GitHub repository here: https://github.ubc.ca/MDS-2022-23/DSCI_572_lab4_missarah","metadata":{"nbgrader":{"grade":false,"grade_id":"cell-4aecf0223bc592cc","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"markdown","source":"## Imports\n<hr>","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:29:08.901597Z","iopub.execute_input":"2023-01-30T23:29:08.901924Z","iopub.status.idle":"2023-01-30T23:29:21.650876Z","shell.execute_reply.started":"2023-01-30T23:29:08.901842Z","shell.execute_reply":"2023-01-30T23:29:21.649673Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom collections import OrderedDict\nimport torch\nfrom torch import nn, optim\nimport memory_profiler\nfrom torchsummary import summary\nimport torchvision\nfrom torchvision import datasets, transforms, utils, models\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\nfrom PIL import Image\n\nplt.rcParams.update({'axes.grid': False})","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:29:21.655039Z","iopub.execute_input":"2023-01-30T23:29:21.655742Z","iopub.status.idle":"2023-01-30T23:29:23.631845Z","shell.execute_reply.started":"2023-01-30T23:29:21.655698Z","shell.execute_reply":"2023-01-30T23:29:23.630938Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Getting Started with Kaggle\n<hr>","metadata":{}},{"cell_type":"markdown","source":"We are going to run this notebook on the cloud using [Kaggle](https://www.kaggle.com). Kaggle offers 30 hours of free GPU usage per week which should be much more than enough for this lab. To get started, follow these steps:\n\n1. Go to https://www.kaggle.com/kernels\n\n2. Make an account if you don't have one, and verify your phone number (to get access to GPUs)\n3. Select `+ New Notebook`\n4. Go to `File -> Import Notebook`\n5. Upload this notebook\n6. On the right-hand side of your Kaggle notebook, make sure:\n  \n  - `Internet` is enabled.\n  \n  - In the `Accelerator` dropdown, choose one of the GPU options when you're ready to use it (you can turn it on/off as you need it).\n    \nOnce you've done all your work on Kaggle, you can download the notebook from Kaggle. That way any work you did on Kaggle won't be lost.","metadata":{"colab_type":"text","id":"91yxVPKkO2qa"}},{"cell_type":"markdown","source":"## Exercise 1: Transfer Learning\n<hr>\n\nrubric={accuracy:15}","metadata":{}},{"cell_type":"markdown","source":"In this exercise you're going to practice transfer learning. We're going to develop a model that can detect the following 6 cat breeds in this Kaggle [dataset](https://www.kaggle.com/solothok/cat-breed):\n\n1. American Short hair\n\n2. Bengal\n3. Maine Soon\n4. Ragdoll\n5. Scottish Fold\n6. Sphinx","metadata":{}},{"cell_type":"markdown","source":"In order to use this dataset \n\n1. Click `+ Add data` at the top right of the notebook.\n\n2. Search for **\"cat-breed\"** and click `Add`","metadata":{}},{"cell_type":"markdown","source":"### 1.1: CNN from Scratch","metadata":{}},{"cell_type":"markdown","source":"In this exercise, you should build a CNN model to classify images of cats based on their breeds.\n\nIn Kaggle, running the follow cell should print out `\"Using device: cuda\"` which means a GPU is available:","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device.type}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:29:23.633322Z","iopub.execute_input":"2023-01-30T23:29:23.634190Z","iopub.status.idle":"2023-01-30T23:29:23.710705Z","shell.execute_reply.started":"2023-01-30T23:29:23.634151Z","shell.execute_reply":"2023-01-30T23:29:23.708211Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"To make use of the GPU, you should:\n1. Move your model to the GPU after creating it using this syntax:\n\n```python\nmodel.to(device)\n```\n\n2. In your training/validation loops, each batch should be moved to the GPU using syntax like:\n\n```python\nfor X, y in dataloader:\n    X, y = X.to(device), y.to(device)\n    ...\n```","metadata":{}},{"cell_type":"markdown","source":"Here are some guidelines for building your binary classification CNN from scratch:\n\n- You may use any architecture you like.\n\n- This is the path to the data in your notebook: `../input/cat-breed/cat-breed/`\n- You should use an `IMAGE_SIZE = 200` pixels in your data loader (the raw images could be any size).\n- **You must train your model for at least 20 epochs and print or plot the accuracy for each epoch on the validation data for us to see.**\n\n>If you want to take a look at the images after making a `train_loader`, try this code:\n\n```python\n# Plot samples\nsample_batch = next(iter(train_loader))\nplt.figure(figsize=(10, 8)); plt.axis(\"off\"); plt.title(\"Sample Training Images\")\nplt.imshow(np.transpose(utils.make_grid(sample_batch[0], padding=1, normalize=True),(1, 2, 0)));\n```","metadata":{}},{"cell_type":"code","source":"TRAIN_DIR = \"../input/cat-breed/cat-breed/TRAIN\"\nVALID_DIR = \"../input/cat-breed/cat-breed/TEST\"\n\nIMAGE_SIZE = (200, 200)\n\ndata_transforms = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor()\n])\n\ntrain_dataset = torchvision.datasets.ImageFolder(root=TRAIN_DIR, transform=data_transforms)\nvalid_dataset = torchvision.datasets.ImageFolder(root=VALID_DIR, transform=data_transforms)\n\nBATCH_SIZE = 64\n\ntrainloader = torch.utils.data.DataLoader(\n    train_dataset,          # our raw data\n    batch_size=BATCH_SIZE,  # the size of batches we want the dataloader to return\n    shuffle=True,           # shuffle our data before batching\n    drop_last=False         # don't drop the last batch even if it's smaller than batch_size\n)\n\nvalidloader = torch.utils.data.DataLoader(\n    valid_dataset,          # our raw data\n    batch_size=BATCH_SIZE,  # the size of batches we want the dataloader to return\n    shuffle=True,           # shuffle our data before batching\n    drop_last=False         # don't drop the last batch even if it's smaller than batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:35:20.010833Z","iopub.execute_input":"2023-01-30T23:35:20.012045Z","iopub.status.idle":"2023-01-30T23:35:20.044052Z","shell.execute_reply.started":"2023-01-30T23:35:20.011999Z","shell.execute_reply":"2023-01-30T23:35:20.043084Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"sample_batch = next(iter(train_loader))\nplt.figure(figsize=(10, 8)); plt.axis(\"off\"); plt.title(\"Sample Training Images\")\nplt.imshow(np.transpose(utils.make_grid(sample_batch[0], padding=1, normalize=True),(1, 2, 0)));","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:50:50.355643Z","iopub.status.idle":"2023-01-30T23:50:50.356040Z","shell.execute_reply.started":"2023-01-30T23:50:50.355831Z","shell.execute_reply":"2023-01-30T23:50:50.355848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trainer(model, criterion, optimizer, trainloader, validloader, epochs=5, verbose=True):\n    \"\"\"Simple training wrapper for PyTorch network.\"\"\"\n    \n    train_loss, valid_loss, valid_accuracy = [], [], []\n    for epoch in range(epochs):  # for each epoch\n        train_batch_loss = 0\n        valid_batch_loss = 0\n        valid_batch_acc = 0\n        \n        # Training\n        for X, y in trainloader:\n            X, y = X.to(device), y.to(device)\n            optimizer.zero_grad()       # Zero all the gradients w.r.t. parameters\n            y_hat = model(X)            # Forward pass to get output\n            loss = criterion(y_hat, y)  # Calculate loss based on output\n            loss.backward()             # Calculate gradients w.r.t. parameters\n            optimizer.step()            # Update parameters\n            train_batch_loss += loss.item()  # Add loss for this batch to running total\n        train_loss.append(train_batch_loss / len(trainloader))\n        \n        # Validation\n        with torch.no_grad():  # this stops pytorch doing computational graph stuff under-the-hood and saves memory and time\n            for X, y in validloader:\n                X, y = X.to(device), y.to(device)\n                y_hat = model(X)\n                _, y_hat_labels = torch.softmax(y_hat, dim=1).topk(1, dim=1)\n                loss = criterion(y_hat, y)\n                valid_batch_loss += loss.item()\n                valid_batch_acc += (y_hat_labels.squeeze() == y).type(torch.float32).mean().item()\n        valid_loss.append(valid_batch_loss / len(validloader))\n        valid_accuracy.append(valid_batch_acc / len(validloader))  # accuracy\n        \n        # Print progress\n        if verbose:\n            print(f\"Epoch {epoch + 1}:\",\n                  f\"Train Loss: {train_loss[-1]:.3f}.\",\n                  f\"Valid Loss: {valid_loss[-1]:.3f}.\",\n                  f\"Valid Accuracy: {valid_accuracy[-1]:.2f}.\")\n    \n    results = {\"train_loss\": train_loss,\n               \"valid_loss\": valid_loss,\n               \"valid_accuracy\": valid_accuracy}\n    return results","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:37:49.671399Z","iopub.execute_input":"2023-01-30T23:37:49.671759Z","iopub.status.idle":"2023-01-30T23:37:49.683958Z","shell.execute_reply.started":"2023-01-30T23:37:49.671727Z","shell.execute_reply":"2023-01-30T23:37:49.683024Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class CNN(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.main = torch.nn.Sequential(\n            \n            torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d((2,2)),\n            \n            torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d((2,2)),\n            \n            torch.nn.Conv2d(in_channels=32, out_channels=8, kernel_size=(3, 3), padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d((2,2)),\n            \n            torch.nn.Flatten(),\n            \n            torch.nn.Linear(5000, 6),\n        )\n\n    def forward(self, x):\n        out = self.main(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:43:14.098779Z","iopub.execute_input":"2023-01-30T23:43:14.099499Z","iopub.status.idle":"2023-01-30T23:43:14.107619Z","shell.execute_reply.started":"2023-01-30T23:43:14.099462Z","shell.execute_reply":"2023-01-30T23:43:14.106679Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model = CNN()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:43:16.658092Z","iopub.execute_input":"2023-01-30T23:43:16.658476Z","iopub.status.idle":"2023-01-30T23:43:16.670651Z","shell.execute_reply.started":"2023-01-30T23:43:16.658446Z","shell.execute_reply":"2023-01-30T23:43:16.669670Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"CNN(\n  (main): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): ReLU()\n    (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU()\n    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (9): Flatten(start_dim=1, end_dim=-1)\n    (10): Linear(in_features=5000, out_features=6, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"summary(model, (3, 200, 200))","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:43:18.228942Z","iopub.execute_input":"2023-01-30T23:43:18.229636Z","iopub.status.idle":"2023-01-30T23:43:18.248473Z","shell.execute_reply.started":"2023-01-30T23:43:18.229600Z","shell.execute_reply":"2023-01-30T23:43:18.247549Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 16, 200, 200]             448\n              ReLU-2         [-1, 16, 200, 200]               0\n         MaxPool2d-3         [-1, 16, 100, 100]               0\n            Conv2d-4         [-1, 32, 100, 100]           4,640\n              ReLU-5         [-1, 32, 100, 100]               0\n         MaxPool2d-6           [-1, 32, 50, 50]               0\n            Conv2d-7            [-1, 8, 50, 50]           2,312\n              ReLU-8            [-1, 8, 50, 50]               0\n         MaxPool2d-9            [-1, 8, 25, 25]               0\n          Flatten-10                 [-1, 5000]               0\n           Linear-11                    [-1, 6]          30,006\n================================================================\nTotal params: 37,406\nTrainable params: 37,406\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.46\nForward/backward pass size (MB): 16.86\nParams size (MB): 0.14\nEstimated Total Size (MB): 17.46\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nresults = trainer(model, criterion, optimizer, trainloader, validloader, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T23:45:16.955349Z","iopub.execute_input":"2023-01-30T23:45:16.955717Z","iopub.status.idle":"2023-01-30T23:50:50.332678Z","shell.execute_reply.started":"2023-01-30T23:45:16.955686Z","shell.execute_reply":"2023-01-30T23:50:50.331527Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss: 1.079. Valid Loss: 1.496. Valid Accuracy: 0.38.\nEpoch 2: Train Loss: 0.979. Valid Loss: 1.412. Valid Accuracy: 0.43.\nEpoch 3: Train Loss: 0.896. Valid Loss: 1.430. Valid Accuracy: 0.43.\nEpoch 4: Train Loss: 0.829. Valid Loss: 1.358. Valid Accuracy: 0.47.\nEpoch 5: Train Loss: 0.766. Valid Loss: 1.584. Valid Accuracy: 0.42.\nEpoch 6: Train Loss: 0.695. Valid Loss: 1.543. Valid Accuracy: 0.45.\nEpoch 7: Train Loss: 0.650. Valid Loss: 1.537. Valid Accuracy: 0.43.\nEpoch 8: Train Loss: 0.567. Valid Loss: 1.606. Valid Accuracy: 0.45.\nEpoch 9: Train Loss: 0.498. Valid Loss: 1.646. Valid Accuracy: 0.43.\nEpoch 10: Train Loss: 0.438. Valid Loss: 1.822. Valid Accuracy: 0.41.\nEpoch 11: Train Loss: 0.379. Valid Loss: 1.836. Valid Accuracy: 0.44.\nEpoch 12: Train Loss: 0.321. Valid Loss: 2.202. Valid Accuracy: 0.39.\nEpoch 13: Train Loss: 0.322. Valid Loss: 2.109. Valid Accuracy: 0.42.\nEpoch 14: Train Loss: 0.251. Valid Loss: 2.076. Valid Accuracy: 0.44.\nEpoch 15: Train Loss: 0.181. Valid Loss: 2.404. Valid Accuracy: 0.41.\nEpoch 16: Train Loss: 0.138. Valid Loss: 2.625. Valid Accuracy: 0.42.\nEpoch 17: Train Loss: 0.124. Valid Loss: 2.677. Valid Accuracy: 0.43.\nEpoch 18: Train Loss: 0.098. Valid Loss: 2.910. Valid Accuracy: 0.41.\nEpoch 19: Train Loss: 0.087. Valid Loss: 3.332. Valid Accuracy: 0.40.\nEpoch 20: Train Loss: 0.079. Valid Loss: 3.259. Valid Accuracy: 0.37.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1.2: Feature Extractor","metadata":{}},{"cell_type":"markdown","source":"In this exercise, you should leverage a pre-trained model customized with your own layer(s) on top, to build a CNN classifier that can identify various cat breeds.\n\n- You can use any model you wish. I used `DenseNet`.\n\n- Train your model for at least 20 epochs.\n\n- Comment on the performance of this model compared to your \"from scratch\" model.","metadata":{}},{"cell_type":"code","source":"densenet = models.densenet121(pretrained=True)\n#densenet.eval();\nfor param in densenet.parameters():  # Freeze parameters so we don't update them\n    param.requires_grad = False\n    \ndensenet.classifier\n\nnew_layers = nn.Sequential(\n    nn.Linear(1024, 500),\n    nn.ReLU(),\n    nn.Linear(500, 6)\n)\ndensenet.classifier = new_layers\n\ndensenet.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(densenet.parameters(), lr=0.001)\nresults = trainer(densenet, criterion, optimizer, trainloader, validloader, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T00:18:12.495856Z","iopub.execute_input":"2023-01-31T00:18:12.496247Z","iopub.status.idle":"2023-01-31T00:24:19.635591Z","shell.execute_reply.started":"2023-01-31T00:18:12.496216Z","shell.execute_reply":"2023-01-31T00:24:19.633522Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss: 0.893. Valid Loss: 0.418. Valid Accuracy: 0.85.\nEpoch 2: Train Loss: 0.270. Valid Loss: 0.286. Valid Accuracy: 0.89.\nEpoch 3: Train Loss: 0.180. Valid Loss: 0.268. Valid Accuracy: 0.91.\nEpoch 4: Train Loss: 0.147. Valid Loss: 0.271. Valid Accuracy: 0.91.\nEpoch 5: Train Loss: 0.149. Valid Loss: 0.326. Valid Accuracy: 0.86.\nEpoch 6: Train Loss: 0.113. Valid Loss: 0.314. Valid Accuracy: 0.88.\nEpoch 7: Train Loss: 0.090. Valid Loss: 0.265. Valid Accuracy: 0.91.\nEpoch 8: Train Loss: 0.071. Valid Loss: 0.254. Valid Accuracy: 0.92.\nEpoch 9: Train Loss: 0.051. Valid Loss: 0.211. Valid Accuracy: 0.91.\nEpoch 10: Train Loss: 0.065. Valid Loss: 0.282. Valid Accuracy: 0.90.\nEpoch 11: Train Loss: 0.056. Valid Loss: 0.223. Valid Accuracy: 0.92.\nEpoch 12: Train Loss: 0.059. Valid Loss: 0.297. Valid Accuracy: 0.90.\nEpoch 13: Train Loss: 0.046. Valid Loss: 0.239. Valid Accuracy: 0.92.\nEpoch 14: Train Loss: 0.034. Valid Loss: 0.262. Valid Accuracy: 0.90.\nEpoch 15: Train Loss: 0.023. Valid Loss: 0.245. Valid Accuracy: 0.90.\nEpoch 16: Train Loss: 0.026. Valid Loss: 0.239. Valid Accuracy: 0.92.\nEpoch 17: Train Loss: 0.028. Valid Loss: 0.259. Valid Accuracy: 0.90.\nEpoch 18: Train Loss: 0.019. Valid Loss: 0.242. Valid Accuracy: 0.91.\nEpoch 19: Train Loss: 0.024. Valid Loss: 0.253. Valid Accuracy: 0.92.\nEpoch 20: Train Loss: 0.020. Valid Loss: 0.298. Valid Accuracy: 0.91.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<b> `DenseNet` is doing much better than scratch model on our train and valid datasets because it is pre-trained model. </b>","metadata":{}},{"cell_type":"markdown","source":"### 1.3: Fine Tuning","metadata":{}},{"cell_type":"markdown","source":"In this final exercise, you should fine-tune your model by updating all or some of the layers during training.\n\n- You can fine-tune as many layers as you like: the whole model, or particular layers. Experiment with both modes of fine-tuning, and find which works better.\n\n- Train your model for at least 20 epochs.\n\n- Comment on the performance of this model compared to your \"from scratch\" and \"feature extractor\" models.","metadata":{}},{"cell_type":"code","source":"densenet = models.densenet121(pretrained=True)\n\n#unfreeze all layers\n\nnew_layers = nn.Sequential(\n    nn.Linear(1024, 500),\n    nn.ReLU(),\n    nn.Linear(500, 6)\n)\n\ndensenet.classifier = new_layers\n\n\ndensenet.to(device);\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(densenet.parameters(), lr=0.001)\nresults = trainer(densenet, criterion, optimizer, trainloader, validloader, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T00:49:41.064917Z","iopub.execute_input":"2023-01-31T00:49:41.065306Z","iopub.status.idle":"2023-01-31T00:57:14.903402Z","shell.execute_reply.started":"2023-01-31T00:49:41.065274Z","shell.execute_reply":"2023-01-31T00:57:14.902342Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss: 0.615. Valid Loss: 0.460. Valid Accuracy: 0.85.\nEpoch 2: Train Loss: 0.313. Valid Loss: 0.567. Valid Accuracy: 0.82.\nEpoch 3: Train Loss: 0.212. Valid Loss: 0.478. Valid Accuracy: 0.85.\nEpoch 4: Train Loss: 0.158. Valid Loss: 0.529. Valid Accuracy: 0.86.\nEpoch 5: Train Loss: 0.108. Valid Loss: 0.388. Valid Accuracy: 0.89.\nEpoch 6: Train Loss: 0.083. Valid Loss: 0.471. Valid Accuracy: 0.87.\nEpoch 7: Train Loss: 0.091. Valid Loss: 0.718. Valid Accuracy: 0.82.\nEpoch 8: Train Loss: 0.104. Valid Loss: 0.551. Valid Accuracy: 0.85.\nEpoch 9: Train Loss: 0.089. Valid Loss: 0.561. Valid Accuracy: 0.87.\nEpoch 10: Train Loss: 0.123. Valid Loss: 0.624. Valid Accuracy: 0.88.\nEpoch 11: Train Loss: 0.100. Valid Loss: 0.521. Valid Accuracy: 0.87.\nEpoch 12: Train Loss: 0.082. Valid Loss: 0.434. Valid Accuracy: 0.88.\nEpoch 13: Train Loss: 0.090. Valid Loss: 0.529. Valid Accuracy: 0.88.\nEpoch 14: Train Loss: 0.056. Valid Loss: 0.357. Valid Accuracy: 0.90.\nEpoch 15: Train Loss: 0.021. Valid Loss: 0.510. Valid Accuracy: 0.88.\nEpoch 16: Train Loss: 0.024. Valid Loss: 0.417. Valid Accuracy: 0.90.\nEpoch 17: Train Loss: 0.055. Valid Loss: 0.493. Valid Accuracy: 0.88.\nEpoch 18: Train Loss: 0.065. Valid Loss: 0.484. Valid Accuracy: 0.90.\nEpoch 19: Train Loss: 0.064. Valid Loss: 0.581. Valid Accuracy: 0.86.\nEpoch 20: Train Loss: 0.075. Valid Loss: 0.549. Valid Accuracy: 0.87.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Exercise 2: Generative Adversarial Networks\n<hr>\n\nrubric={accuracy:15}","metadata":{}},{"cell_type":"markdown","source":"In this exercise you're going to practice building a generative adversarial network (GAN).\n\nGANs are incredibly hard to train especially with small datasets, so you may not get good results in this exercise. But don't worry about that, it is just important to get some practice and experience with these types of NNs.\n\n> For this exercise, you're not limited to a particular dataset, you can use any dataset you like. The `cat-breed` or any other suitable one on Kaggle is acceptable, as long as you can show the progress of your trained GAN on it.","metadata":{}},{"cell_type":"markdown","source":"### 2.1: Preparing the Data","metadata":{}},{"cell_type":"markdown","source":"In Kaggle, running the follow cell should print out `\"Using device: cuda\"` which means a GPU is available:","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device.type}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To make use of the GPU, you should:\n- Move your model to the GPU after creating it with the syntax:\n\n```python\nmodel.to(device)\n```\n\n- In your training loop, each batch should be moved to the GPU using syntax like:\n\n```python\nfor X, _ in dataloader:\n    X = X.to(device)\n    ...\n```\n\n- Note above that we don't need the labels for training a GAN, so I ignore it by un-packing it into an underscore `_` (which is typically Python convention for variables we don't need).","metadata":{}},{"cell_type":"markdown","source":"Okay, prepare the data by creating a `data_loader`. This is the path to the data in your notebook if you choose to use the `cat-breed` dataset: `../input/cat-breed/cat-breed/`.\n\n>If you want to take a look at the images after making a `data_loader`, try this code:\n\n```python\n# Plot samples\nsample_batch = next(iter(data_loader))\nplt.figure(figsize=(10, 8)); plt.axis(\"off\"); plt.title(\"Sample Training Images\")\nplt.imshow(np.transpose(utils.make_grid(sample_batch[0], padding=1, normalize=True),(1, 2, 0)));\n```","metadata":{}},{"cell_type":"code","source":"...","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2: Create the Generator","metadata":{}},{"cell_type":"markdown","source":"Now, we need to create a generator for our GAN. You can reuse/modify the code from Lecture 8, or build your own.","metadata":{}},{"cell_type":"code","source":"...","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3: Create the Discriminator","metadata":{}},{"cell_type":"markdown","source":"Now, we need to create a discriminator for our GAN. You can reuse/modify the code from Lecture 8, or build your own.","metadata":{}},{"cell_type":"code","source":"...","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.4: Initialize Weights","metadata":{}},{"cell_type":"markdown","source":"GANs can be quite sensitive to the initial weights assigned to each layer when we instantiate the model. Instantiate your generator and discriminator and then specify their initial weights as follows:\n\n- `Conv2d()` layers: normal distribution with `mean=0.0` and `std=0.02`\n\n- `ConvTranspose2d()` layers: normal distribution with `mean=0.0` and `std=0.02`\n\n- `BatchNorm2d()` layers: normal distribution with `mean=1.0` and `std=0.02` for the weights, zeroes for the biases\n\n- Use `LATENT_SIZE = 100`","metadata":{}},{"cell_type":"code","source":"...","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.5: Train your GAN","metadata":{}},{"cell_type":"markdown","source":"You now have all the ingredients you need now to train a GAN, so give it a go!\n\nYou should track the loss of your model as epochs progress and show at least one example of an image output by your trained generator (better yet, record the evolution over time of how your generator is doing, like we did in Lecture 8). **Your results may not be great and that's perfectly okay, you should just show _something_**.\n\nHere are some tips:\n\n- You will likely need to train for at least `NUM_EPOCHS=100` (and maybe more).\n\n- I find that the hardest part about training GANs is that the discriminator \"overpowers\" the generator, making it hard for the generator to learn how to create realistic images. There are lots of things you can do to try and balance your generator and discriminator, such as: play with the optimizer's hyperparameters, change the architectures of your models, etc.\n\n- Here's a good set of [tips and tricks for training GANs](https://github.com/soumith/ganhacks).\n\n- Once again, GANs are notoriously difficult to train (even more so with smaller data sets like we have here). Don't worry if you're not getting amazing results. This is all about practice.","metadata":{}},{"cell_type":"code","source":"...","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}